{"cells":[{"cell_type":"markdown","metadata":{"editable":true,"trusted":true},"source":["# AWS Glue Studio Notebook\n","##### You are now running a AWS Glue Studio notebook; To start using your notebook you need to start an AWS Glue Interactive Session.\n"]},{"cell_type":"markdown","metadata":{"editable":true,"trusted":true},"source":["#### Optional: Run this cell to see available notebook commands (\"magics\").\n"]},{"cell_type":"code","execution_count":1,"metadata":{"editable":true,"trusted":true,"vscode":{"languageId":"python_glue_session"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Welcome to the Glue Interactive Sessions Kernel\n","For more information on available magic commands, please type %help in any new cell.\n","\n","Please view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\n","Installed kernel version: 1.0.5 \n"]}],"source":["# %help"]},{"cell_type":"markdown","metadata":{"editable":true,"trusted":true},"source":["####  Run this cell to set up and start your interactive session.\n"]},{"cell_type":"code","execution_count":1,"metadata":{"editable":true,"trusted":true,"vscode":{"languageId":"python_glue_session"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Welcome to the Glue Interactive Sessions Kernel\n","For more information on available magic commands, please type %help in any new cell.\n","\n","Please view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\n","Installed kernel version: 1.0.5 \n","Current idle_timeout is None minutes.\n","idle_timeout has been set to 20 minutes.\n","Setting Glue version to: 4.0\n","Previous worker type: None\n","Setting new worker type to: G.1X\n","Previous number of workers: None\n","Setting new number of workers to: 2\n","Trying to create a Glue session for the kernel.\n","Session Type: glueetl\n","Worker Type: G.1X\n","Number of Workers: 2\n","Idle Timeout: 20\n","Session ID: fbf5e0fa-92fc-442b-8c21-d88bdb0c82c6\n","Applying the following default arguments:\n","--glue_kernel_version 1.0.5\n","--enable-glue-datacatalog true\n","Waiting for session fbf5e0fa-92fc-442b-8c21-d88bdb0c82c6 to get into ready status...\n","Session fbf5e0fa-92fc-442b-8c21-d88bdb0c82c6 has been created.\n","\n"]}],"source":["%idle_timeout 20\n","%glue_version 4.0\n","%worker_type G.1X\n","%number_of_workers 2\n","\n","import sys\n","from awsglue.transforms import *\n","from awsglue.utils import getResolvedOptions\n","from pyspark.context import SparkContext\n","from awsglue.context import GlueContext\n","from awsglue.job import Job\n","\n","sc = SparkContext.getOrCreate()\n","glueContext = GlueContext(sc)\n","spark = glueContext.spark_session\n","job = Job(glueContext)"]},{"cell_type":"code","execution_count":2,"metadata":{"tags":[],"trusted":true,"vscode":{"languageId":"python_glue_session"}},"outputs":[{"name":"stdout","output_type":"stream","text":["\n"]}],"source":["# important! using python min, max won't work\n","from pyspark.sql.functions import col, min, max, sum, avg, count, countDistinct, row_number\n","from pyspark.sql.window import Window\n","\n","# https://spark.apache.org/docs/latest/sql-ref-datatypes.html\n","from pyspark.sql.types import StructType, StructField, BooleanType, ByteType, ShortType, IntegerType, StringType, FloatType, DoubleType"]},{"cell_type":"markdown","metadata":{},"source":["## aisles\n","read as csv, save as parquet, then read from parquet"]},{"cell_type":"code","execution_count":5,"metadata":{"tags":[],"trusted":true,"vscode":{"languageId":"python_glue_session"}},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- aisle_id: integer (nullable = true)\n"," |-- aisle: string (nullable = true)\n","\n","row count: 134\n"]}],"source":["aisles_schema = StructType([\n","    StructField(\"aisle_id\", IntegerType(), True),\n","    StructField(\"aisle\", StringType(), True)\n","])\n","aisles = spark.read.csv(\"s3://sam-raw/aisles/aisles.csv\", header=True, schema=aisles_schema)\n","aisles.write.mode(\"overwrite\").parquet(\"s3://sam-raw-parquet/aisles/\")\n","aisles = spark.read.parquet('s3://sam-raw-parquet/aisles')\n","aisles.printSchema()\n","print(f'row count: {aisles.count()}')"]},{"cell_type":"markdown","metadata":{},"source":["## departments\n","read as csv, save as parquet, then read from parquet"]},{"cell_type":"code","execution_count":6,"metadata":{"tags":[],"trusted":true,"vscode":{"languageId":"python_glue_session"}},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- department_id: integer (nullable = true)\n"," |-- department: string (nullable = true)\n","\n","row count: 21\n"]}],"source":["departments_schema = StructType([\n","    StructField(\"department_id\", IntegerType(), True),\n","    StructField(\"department\", StringType(), True)\n","])\n","departments = spark.read.csv(\"s3://sam-raw/departments/departments.csv\", header=True, schema=departments_schema)\n","departments.write.mode(\"overwrite\").parquet(\"s3://sam-raw-parquet/departments/\")\n","departments = spark.read.parquet('s3://sam-raw-parquet/departments') # read as parquet\n","departments.printSchema()\n","print(f'row count: {departments.count()}')"]},{"cell_type":"markdown","metadata":{},"source":["## products\n","read as csv, save as parquet, then read from parquet"]},{"cell_type":"code","execution_count":7,"metadata":{"tags":[],"trusted":true,"vscode":{"languageId":"python_glue_session"}},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- product_id: integer (nullable = true)\n"," |-- product_name: string (nullable = true)\n"," |-- aisle_id: integer (nullable = true)\n"," |-- department_id: integer (nullable = true)\n","\n","row count: 49688\n"]}],"source":["products_schema = StructType([\n","    StructField(\"product_id\", IntegerType(), True),\n","    StructField(\"product_name\", StringType(), True),\n","    StructField(\"aisle_id\", IntegerType(), True),\n","    StructField(\"department_id\", IntegerType(), True)\n","])\n","products = spark.read.csv(\"s3://sam-raw/products/products.csv\", header=True, schema=products_schema)\n","products.write.mode(\"overwrite\").parquet(\"s3://sam-raw-parquet/products/\")\n","products = spark.read.parquet('s3://sam-raw-parquet/products') # read as parquet\n","products.printSchema()\n","print(f'row count: {products.count()}')"]},{"cell_type":"markdown","metadata":{"tags":[]},"source":["## denorm products\n","join with aisles and departments, save to transformed"]},{"cell_type":"code","execution_count":8,"metadata":{"tags":[],"trusted":true,"vscode":{"languageId":"python_glue_session"}},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- product_id: integer (nullable = true)\n"," |-- product_name: string (nullable = true)\n"," |-- aisle_id: integer (nullable = true)\n"," |-- aisle: string (nullable = true)\n"," |-- department_id: integer (nullable = true)\n"," |-- department: string (nullable = true)\n"]}],"source":["products_denorm = products\\\n","                    .join(aisles, products.aisle_id==aisles.aisle_id, 'inner')\\\n","                    .join(departments, products.department_id==departments.department_id, 'inner')\\\n","                    .select(products.product_id,\n","                            products.product_name,\n","                            products.aisle_id,\n","                            aisles.aisle,\n","                            products.department_id,\n","                            departments.department\n","                           )\n","products_denorm.printSchema()\n","products_denorm.write.mode(\"overwrite\").parquet(\"s3://sam-transformed/products/\")"]},{"cell_type":"markdown","metadata":{},"source":["## orders\n","read as csv, partition by eval_set, save as parquet, then read from parque"]},{"cell_type":"code","execution_count":9,"metadata":{"tags":[],"trusted":true,"vscode":{"languageId":"python_glue_session"}},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- order_id: integer (nullable = true)\n"," |-- user_id: integer (nullable = true)\n"," |-- order_number: integer (nullable = true)\n"," |-- order_dow: byte (nullable = true)\n"," |-- order_hour_of_day: byte (nullable = true)\n"," |-- days_since_prior_order: float (nullable = true)\n"," |-- eval_set: string (nullable = true)\n","\n","row count: 3421083\n","+-----------------+-----------------+\n","|min(order_number)|max(order_number)|\n","+-----------------+-----------------+\n","|                1|              100|\n","+-----------------+-----------------+\n","\n","+---------------------------+---------------------------+\n","|min(days_since_prior_order)|max(days_since_prior_order)|\n","+---------------------------+---------------------------+\n","|                        0.0|                       30.0|\n","+---------------------------+---------------------------+\n"]}],"source":["orders_schema = StructType([\n","    StructField(\"order_id\", IntegerType(), True),\n","    StructField(\"user_id\", IntegerType(), True),\n","    StructField(\"eval_set\", StringType(), True),\n","    StructField(\"order_number\", IntegerType(), True),\n","    StructField(\"order_dow\", ByteType(), True),\n","    StructField(\"order_hour_of_day\", ByteType(), True),\n","    StructField(\"days_since_prior_order\", FloatType(), True)\n","])\n","orders = spark.read.csv(\"s3://sam-raw/orders/orders.csv\", header=True, schema=orders_schema)\n","orders.write.partitionBy(\"eval_set\").mode(\"overwrite\").parquet(\"s3://sam-raw-parquet/orders/\")\n","orders = spark.read.parquet('s3://sam-raw-parquet/orders') # read as parquet\n","orders.printSchema()\n","print(f'row count: {orders.count()}')\n","orders.agg(min('order_number'), max('order_number')).show()\n","orders.agg(min('days_since_prior_order'), max('days_since_prior_order')).show()"]},{"cell_type":"code","execution_count":10,"metadata":{"tags":[],"trusted":true,"vscode":{"languageId":"python_glue_session"}},"outputs":[{"name":"stdout","output_type":"stream","text":["row count: 3214874\n"]}],"source":["# filter by eval_set=prior\n","orders_prior = orders.where(orders.eval_set=='prior').select(*[c for c in orders.columns if c!='eval_set'])\n","print(f'row count: {orders_prior.count()}')\n","orders_prior.write.mode(\"overwrite\").parquet(\"s3://sam-transformed/orders_prior/\")"]},{"cell_type":"markdown","metadata":{},"source":["## order_products\n","read as csv, save as parquet, then read from parque"]},{"cell_type":"code","execution_count":11,"metadata":{"tags":[],"trusted":true,"vscode":{"languageId":"python_glue_session"}},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- order_id: integer (nullable = true)\n"," |-- product_id: integer (nullable = true)\n"," |-- add_to_cart_order: integer (nullable = true)\n"," |-- reordered: boolean (nullable = true)\n","\n","row count: 33819106\n"]}],"source":["# takes 1 minute to run\n","order_products_schema = StructType([\n","    StructField(\"order_id\", IntegerType(), True),\n","    StructField(\"product_id\", IntegerType(), True),\n","    StructField(\"add_to_cart_order\", IntegerType(), True),\n","    StructField(\"reordered\", IntegerType(), True)\n","])\n","order_products = spark.read.csv(\"s3://sam-raw/order_products\", header=True, schema=order_products_schema)\n","order_products = order_products.withColumn(\"reordered\", col(\"reordered\").cast(\"boolean\"))\n","order_products.write.mode(\"overwrite\").parquet(\"s3://sam-raw-parquet/order_products/\")\n","order_products = spark.read.parquet('s3://sam-raw-parquet/order_products') # read as parquet\n","order_products.printSchema()\n","print(f'row count: {order_products.count()}')"]},{"cell_type":"code","execution_count":12,"metadata":{"tags":[],"trusted":true,"vscode":{"languageId":"python_glue_session"}},"outputs":[{"name":"stdout","output_type":"stream","text":["\n"]}],"source":["# takes 20 seconds to run\n","order_products_prior = orders_prior\\\n","                        .join(order_products, orders_prior.order_id==order_products.order_id, 'inner')\\\n","                        .select(orders_prior.order_id,\n","                                orders_prior.user_id,\n","                                orders_prior.order_number,\n","                                orders_prior.order_dow,\n","                                orders_prior.order_hour_of_day,\n","                                orders_prior.days_since_prior_order,\n","                                order_products.product_id,\n","                                order_products.add_to_cart_order,\n","                                order_products.reordered\n","                               )\n","order_products_prior.write.mode(\"overwrite\").parquet(\"s3://sam-transformed/order_products_prior/\")"]},{"cell_type":"markdown","metadata":{},"source":["## Q2\n","```sql\n","select \n","    user_id, \n","    max(order_number) as max_order_number, \n","    sum(days_since_prior_order) as sum_days_since_prior_order, \n","    avg(days_since_prior_order) as avg_days_since_prior_order\n","from orders\n","group by user_id;\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"python_glue_session"}},"outputs":[],"source":["# orders = spark.read.parquet('s3://sam-raw-parquet/orders') # read as parquet"]},{"cell_type":"code","execution_count":14,"metadata":{"tags":[],"trusted":true,"vscode":{"languageId":"python_glue_session"}},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------+----------------+--------------------------+--------------------------+\n","|user_id|max_order_number|sum_days_since_prior_order|avg_days_since_prior_order|\n","+-------+----------------+--------------------------+--------------------------+\n","|      1|              11|                     190.0|                      19.0|\n","|      2|              15|                     228.0|        16.285714285714285|\n","|      3|              13|                     144.0|                      12.0|\n","|      4|               6|                      85.0|                      17.0|\n","|      5|               5|                      46.0|                      11.5|\n","+-------+----------------+--------------------------+--------------------------+\n","only showing top 5 rows\n","\n","row count: 206209\n"]}],"source":["user_features_1 = orders.groupBy('user_id').agg(max('order_number').alias('max_order_number'),\n","                                               sum('days_since_prior_order').alias('sum_days_since_prior_order'),\n","                                               avg('days_since_prior_order').alias('avg_days_since_prior_order')\n","                                               )\n","user_features_1.orderBy('user_id').show(5)\n","print(f'row count: {user_features_1.count()}')\n","# save aggregated result as one part\n","user_features_1.write.mode(\"overwrite\").parquet(\"s3://sam-transformed/user_features_1/\")"]},{"cell_type":"markdown","metadata":{},"source":["## Q3\n","```sql\n","SELECT\n","    user_id,\n","    COUNT(product_id) AS total_products_count,\n","    COUNT(DISTINCT product_id) AS total_distinct_products_count, \n","    SUM(CASE WHEN reordered = 1 THEN 1 ELSE 0 END) * 1.0 / \n","    SUM(CASE WHEN order_number > 1 THEN 1 ELSE 0 END) AS reorder_ratio\n","FROM order_products_prior\n","GROUP BY user_id;\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"python_glue_session"}},"outputs":[],"source":["# order_products_prior = spark.read.parquet('s3://sam-transformed/order_products_prior') # read as parquet"]},{"cell_type":"code","execution_count":15,"metadata":{"tags":[],"trusted":true,"vscode":{"languageId":"python_glue_session"}},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------+--------------+-----------------------+-------------------+\n","|user_id|total_products|total_distinct_products|      reorder_ratio|\n","+-------+--------------+-----------------------+-------------------+\n","|      1|            59|                     18| 0.7592592592592593|\n","|      2|           195|                    102|  0.510989010989011|\n","|      3|            88|                     33| 0.7051282051282052|\n","|      4|            18|                     17|0.07142857142857142|\n","|      5|            37|                     23| 0.5384615384615384|\n","+-------+--------------+-----------------------+-------------------+\n","only showing top 5 rows\n","\n","row count: 206209\n"]}],"source":["user_features_2 = order_products_prior.groupBy('user_id').agg(count('product_id').alias('total_products'),\n","                                                              countDistinct('product_id').alias('total_distinct_products'),\n","                                                              (sum(col('reordered').cast('int'))/\n","                                                               sum((col('order_number')>1).cast('int'))).alias('reorder_ratio')\n","                                                            )\n","user_features_2.orderBy('user_id').show(5)\n","print(f'row count: {user_features_2.count()}')\n","user_features_2.write.mode(\"overwrite\").parquet(\"s3://sam-transformed/user_features_2/\")"]},{"cell_type":"markdown","metadata":{},"source":["## Q4\n","```sql\n","SELECT\n","    user_id,\n","    product_id,\n","    COUNT(order_id) AS total_orders,\n","    MIN(order_number) AS min_order_number,\n","    MAX(order_number) AS max_order_number,\n","    AVG(add_to_cart_order) AS avg_add_to_cart_order\n","FROM order_products_prior\n","GROUP BY user_id, product_id;\n","```"]},{"cell_type":"code","execution_count":16,"metadata":{"tags":[],"trusted":true,"vscode":{"languageId":"python_glue_session"}},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------+----------+------------+----------------+----------------+---------------------+\n","|user_id|product_id|total_orders|min_order_number|max_order_number|avg_add_to_cart_order|\n","+-------+----------+------------+----------------+----------------+---------------------+\n","|      1|       196|          10|               1|              10|                  1.4|\n","|      1|     10258|           9|               2|              10|   3.3333333333333335|\n","|      1|     10326|           1|               5|               5|                  5.0|\n","|      1|     12427|          10|               1|              10|                  3.3|\n","|      1|     13032|           3|               2|              10|    6.333333333333333|\n","+-------+----------+------------+----------------+----------------+---------------------+\n","only showing top 5 rows\n","\n","row count: 13307953\n"]}],"source":["up_features = order_products_prior.groupBy('user_id', 'product_id').agg(count('order_id').alias('total_orders'),\n","                                                                        min('order_number').alias('min_order_number'),\n","                                                                        max('order_number').alias('max_order_number'),\n","                                                                        avg('add_to_cart_order').alias('avg_add_to_cart_order')\n","                                                                       )\n","up_features.orderBy('user_id', 'product_id').show(5)\n","print(f'row count: {up_features.count()}')\n","up_features.write.mode(\"overwrite\").parquet(\"s3://sam-transformed/up_features/\")"]},{"cell_type":"markdown","metadata":{},"source":["## Q5\n","```sql\n","SELECT \n","    product_id,\n","    COUNT(product_id) AS total_products,\n","    SUM(reordered) AS total_reordered,\n","    SUM(CASE WHEN product_seq_time = 1 THEN 1 ELSE 0 END) AS product_seq_time_is_1,\n","    SUM(CASE WHEN product_seq_time = 2 THEN 1 ELSE 0 END) AS product_seq_time_is_2\n","FROM (\n","    SELECT\n","        product_id,\n","        reordered,\n","        ROW_NUMBER() OVER (PARTITION BY user_id, product_id ORDER BY order_number ASC) AS product_seq_time\n","    FROM order_products_prior\n",") prod_seq\n","GROUP BY product_id;\n","```"]},{"cell_type":"code","execution_count":17,"metadata":{"tags":[],"trusted":true,"vscode":{"languageId":"python_glue_session"}},"outputs":[{"name":"stdout","output_type":"stream","text":["+----------+--------------+---------------+---------------------+---------------------+\n","|product_id|total_products|total_reordered|product_seq_time_is_1|product_seq_time_is_2|\n","+----------+--------------+---------------+---------------------+---------------------+\n","|         1|          1852|           1136|                  716|                  276|\n","|         2|            90|             12|                   78|                    8|\n","|         3|           277|            203|                   74|                   36|\n","|         4|           329|            147|                  182|                   64|\n","|         5|            15|              9|                    6|                    4|\n","+----------+--------------+---------------+---------------------+---------------------+\n","only showing top 5 rows\n","\n","row count: 49677\n"]}],"source":["prod_seq = order_products_prior.withColumn('product_seq_time', \n","                                           row_number().over(Window\\\n","                                                             .partitionBy('user_id', 'product_id')\\\n","                                                             .orderBy(col('order_number').asc())\n","                                                            )\n","                                          ).select('product_id', 'reordered', 'product_seq_time')\n","\n","prd_features = prod_seq.groupBy('product_id').agg(count('product_id').alias('total_products'),\n","                                                  sum(col('reordered').cast('int')).alias('total_reordered'),\n","                                                  sum((col('product_seq_time')==1).cast('int')).alias('product_seq_time_is_1'),\n","                                                  sum((col('product_seq_time')==2).cast('int')).alias('product_seq_time_is_2')\n","                                                 )\n","prd_features.orderBy('product_id').show(5)\n","print(f'row count: {prd_features.count()}')\n","prd_features.write.mode(\"overwrite\").parquet(\"s3://sam-transformed/prd_features/\")"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"python_glue_session"}},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Glue PySpark","language":"python","name":"glue_pyspark"},"language_info":{"codemirror_mode":{"name":"python","version":3},"file_extension":".py","mimetype":"text/x-python","name":"Python_Glue_Session","pygments_lexer":"python3"}},"nbformat":4,"nbformat_minor":4}
